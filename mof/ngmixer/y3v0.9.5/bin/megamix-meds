#!/cvmfs/des.opensciencegrid.org/2015_Q2/eeups/SL6/eups/packages/Linux64/python/2.7.9+1/bin/python
"""
Process the input meds files in chunks

Possible commands are:
    setup - setup jobs
    setup-nbrs - set up jobs for neighbor finding
    collate - combine job outputs into a single file
    verify - verify that all job outputs are present and OK
    clean - clean all outputs from a run
    archive - run after collate to delete intermediate files and tar logs
    link - make symlinks to all final outputs under {run}/output
    collate-link - collate and link the final outputs

You must have the following environment variables set
    $NGMIXER_OUTPUT_DIR - base output dir
    $TMPDIR - temporary directory for work

TODO: 
    - work on list of tile ids
"""

from __future__ import print_function
try:
    xrange
except:
    xrange=range

import os
import sys
import numpy
import meds
import fitsio
import glob

import ngmixer
from ngmixer import files
from ngmixer.files import read_yaml
from ngmixer.megamixer import NGMegaMixer
from ngmixer.megamixer import SLACNGMegaMixer,SLACArrayNGMegaMixer
from ngmixer.megamixer import CakeNGMegaMixer


from argparse import ArgumentParser
from argparse import RawTextHelpFormatter
parser = ArgumentParser(
    description=__doc__,
    formatter_class=RawTextHelpFormatter,
)

parser.add_argument('ngmix_config',help='config file path')
parser.add_argument('command',help='command to run')
parser.add_argument(
    'meds_files',
    nargs='+',
    help=('the meds files to process, or a yaml file '
          'describing the tile set to use'),
)

parser.add_argument("--walltime",default='48:00',
                  help=("wall time for queue determination (e.g. in lsf)"))
parser.add_argument("--walltime-e",default='4:00',
                  help=("esimated wall time for scheduling (e.g. in lsf)"))
parser.add_argument("--ncores",type=int,default=1,
                  help=("number of cores per job"))

parser.add_argument("--system",default='shell',
                  help=("name of system for jobs"))

parser.add_argument("--queue",default=None,
                  help=("queue to submit to"))

parser.add_argument('--missing',action='store_true',default=False,
                    help="write scripts only for missing output files")

parser.add_argument('--noblind',action='store_true',default=False,
                  help="don't blind the catalog")

parser.add_argument('--clobber',action='store_true',default=False,
                  help="clobber existing catalog, else skip over")

parser.add_argument('--skip-errors',action='store_true',default=False,
                  help="skip over errors")

parser.add_argument('--nocompress',action='store_true',default=False,
                  help="do not compress when archiving logs")

parser.add_argument("--verbosity", default=0, type=int,
                  help=("set verbosity level"))

parser.add_argument("--seed", default=None,type=int,
                  help=("random seed to make seeds for jobs.  "
                        "If not sent, is gotten from the config file"))

parser.add_argument('--desdm',action='store_true',
                  help="the MEDS files, psf maps are DESDM style")

class MegaMixer(dict):
    """
    conf has ngmix config plus
    """
    def __init__(self, ngmix_config, psf_map_files, meds_files,
                 walltime='48:00',
                 walltime_e='4:00',
                 ncores=1,
                 missing=False,
                 blind=True,
                 skip_errors=False,
                 clobber=False,
                 seed=None):
        self.ngmix_config    = os.path.abspath( ngmix_config )
        self.psf_map_files   = [os.path.abspath(f) for f in psf_map_files]
        self.missing=missing
        self.walltime=walltime
        self.walltime_e=walltime_e
        self.ncores=ncores

        self.blind=blind
        self.skip_errors=skip_errors
        self.clobber=clobber

        self._load_config()
        self._make_rng(seed=seed)

        self.meds_files=[os.path.abspath(mf) for mf in meds_files]
        meds_list = [meds.MEDS(f) for f in self.meds_files]

        ngmixer.imageio.medsio.verify_meds(meds_list)

        self.meds_string=' '.join(self.meds_files)

        self.info= files.get_meds_info(meds_files[0])

        self._set_files()

    def setup(self):
        """
        make directories, write scripts
        """

        print("setting up scripts")

        self._set_chunk_ranges()
        self._make_scripts()

    def setup_nbrs(self):
        """
        make directories, write scripts
        """

        print("setting up nbrs scripts")
        self._write_nbrs_script()

    def collate(self):
        """
        concatenate all the chunk files, adding in
        some calculated information such as mags
        """

        self._set_chunk_ranges()

        cls = ngmixer.megamixer.concat_io.get_concat_class(
            self.conf['collate']['concat_type'],
        )
        flist = []
        for chunk,rng in enumerate(self.chunk_ranges):
            fname = self._get_chunk_file(chunk,rng,ext='.fits')
            flist.append(fname)

        collated_file=files.get_collated_file_fromfile(
            self.meds_files[0],
            self.conf['run'],
            blind=self.blind,
        )

        concatter = cls(
            self.ngmix_config,
            flist,
            collated_file,
            bands=self.conf['jobs']['bands'],
            blind=self.blind,
            clobber=self.clobber,
            skip_errors=self.skip_errors,
        )

        concatter.concat()


    def _make_scripts(self):
        """
        write the scripts
        """
        for chunk,rng in enumerate(self.chunk_ranges):
            self._write_script(chunk, rng)

    def _write_script(self, chunk, rng):

        self._make_chunk_dir(chunk, rng)

        fmt=self._get_script_template()
        args = {}

        output_file  = self._get_chunk_file(chunk,rng,ext='.fits')
        logfile      = self._get_chunk_file(chunk,rng,ext='.log')


        args['ngmix_config'] = self.ngmix_config
        args['psf_maps']     = ','.join(self.psf_map_files)
        args['meds_files']   = self.meds_string
        args['output_file']  = output_file
        args['logfile']      = logfile
        args['start']        = rng[0]
        args['stop']         = rng[1]

        args['mof_opt'] = ''
        model_nbrs = self.conf.get('model_nbrs',False)
        if model_nbrs:
            fof_file = self._get_fof_file(ext='.fits')
            args['fof_opt'] = '--fof-file=%s'% fof_file 

            nbrs_file = self._get_nbrs_file(ext='.fits')
            args['nbrs_opt'] = '--nbrs-file=%s'% nbrs_file 

        else:
            args['fof_opt'] = ''
            args['nbrs_opt'] = ''

            if 'correct_meds' in self.conf:
                mof_file = self._get_mof_file()
                args['mof_opt'] = '--mof-file=%s' % mof_file

        seed = self.rng.randint(low=1,high=1000000000)
        args['seed_opt'] = '--seed=%d' % seed

        scr = fmt.format(**args)

        script_name = self._get_chunk_file(chunk,rng,ext='.sh')

        dowrite=True
        if self.missing:
            if os.path.exists(script_name):
                os.remove(script_name)
            if os.path.exists(output_file):
                dowrite=False

        if dowrite:
            print("writing:",script_name)
            with open(script_name,'w') as fp:
                fp.write(scr)

            os.system('chmod 755 %s' % script_name)

        return dowrite, script_name

    def _write_nbrs_script(self):

        self._make_nbrs_dir()

        fmt=self._get_nbrs_script_template()
        args = {}

        logfile      = self._get_nbrs_file(ext='.log')

        args['ngmix_config'] = self.ngmix_config
        args['meds_file']    = self.meds_files[0]
        args['logfile']      = logfile

        scr = fmt.format(**args)

        script_name = self._get_nbrs_file(ext='.sh')

        print("writing:",script_name)
        with open(script_name,'w') as fp:
            fp.write(scr)

        os.system('chmod 755 %s' % script_name)


    def _get_mof_file(self):
        """
        mof file used for subtracting neighbor light
        """

        mof_file = files.get_collated_file_fromfile(
            self.meds_files[0],
            self.conf['correct_meds']['mof_run'],
        )
        return mof_file

    def _make_chunk_dir(self, chunk, rng):
        f=files.get_chunk_file_fromfile(
            self.meds_files[0],
            self.conf['run'],
            rng,
        )
        files.makedirs_fromfile(f)

    def _get_chunk_file(self, chunk, rng, ext='.fits'):
        fname = files.get_chunk_file_fromfile(
            self.meds_files[0],
            self.conf['run'],
            rng,
            missing=self.missing,
            ext=ext,
        )
        return expand_path(fname)

    def _get_nbrs_file(self, ext='.fits'):
        fname = files.get_nbrs_file_fromfile(
            self.meds_files[0],
            self.conf['run'],
            ext=ext,
        )
        return expand_path(fname)

    def _get_fof_file(self, ext='.fits'):
        fname = files.get_fof_file_fromfile(
            self.meds_files[0],
            self.conf['run'],
            ext=ext,
        )
        return expand_path(fname)


    def _make_nbrs_dir(self):
        f=self._get_nbrs_file()
        files.makedirs_fromfile(f)

    def _get_script_template(self):
        template=r"""#!/bin/bash

if [[ -n $_CONDOR_SCRATCH_DIR ]]; then
    # the condor system creates a scratch directory for us,
    # and cleans up afterward
    tmpdir=$_CONDOR_SCRATCH_DIR
    export TMPDIR=$tmpdir
else
    # otherwise use the TMPDIR
    tmpdir=$TMPDIR
    mkdir -p $tmpdir
fi

logfile="{logfile}"

logbase=$(basename $logfile)
tmplog=$tmpdir/$logbase


config="{ngmix_config}"

psf_maps="{psf_maps}"

meds="{meds_files}"

outfile="{output_file}"
start={start}
stop={stop}

ngmixit                                   \
    --fof-range=$start,$stop              \
    --work-dir=$tmpdir                    \
    --psf-map="$psf_maps"                 \
    {nbrs_opt}                            \
    {fof_opt}                             \
    {mof_opt}                             \
    {seed_opt}                            \
    $config $outfile $meds &> $tmplog


mv -vf $tmplog $logfile
"""

        return template

    def _get_nbrs_script_template(self):
        template=r"""#!/bin/bash

if [[ -n $_CONDOR_SCRATCH_DIR ]]; then
    # the condor system creates a scratch directory for us,
    # and cleans up afterward
    tmpdir=$_CONDOR_SCRATCH_DIR
    export TMPDIR=$tmpdir
else
    # otherwise use the TMPDIR
    tmpdir=$TMPDIR
    mkdir -p $tmpdir
fi


logfile="{logfile}"

logbase=$(basename $logfile)
tmplog=$tmpdir/$logbase

config="{ngmix_config}"
meds="{meds_file}"

ngmixer-meds-make-nbrs-data $config $meds &> $tmplog
mv -vf $tmplog $logfile
"""

        return template



    def _set_files(self):
        files={
            'ngmix_config':self.ngmix_config,
            'meds_files':self.meds_files,
        }

        self.files=files

    def _get_num(self):

        model_nbrs = self.conf.get('model_nbrs',False)
        if model_nbrs:
            fname = self._get_fof_file()
            fofs = fitsio.read(fname)
            num = numpy.unique(fofs['fofid']).size
        else:
            fname=self.meds_files[0]

            if not os.path.exists(fname):
                raise ngmixer.util.MissingDataError("missing meds file: %s" % fname)

            with fitsio.FITS(fname) as fits:
                num = fits['object_data'].get_nrows()

        return num


    def _set_chunk_ranges(self):

        if hasattr(self, 'chunk_ranges'):
            return

        files=self.files

        # could be number of objects or number of
        # fof groups
        nrows = self._get_num()

        chunksize=self.jobs_conf['chunksize']
        nchunks = nrows//chunksize
        if nchunks*chunksize < nrows:
            nchunks += 1

        chunk_ranges = []
        for chunk in xrange(nchunks):
            sr = chunk*chunksize
            sp = sr + chunksize - 1
            if sp >= nrows:
                sp = nrows-1
            chunk_ranges.append([sr,sp])

        self.chunk_ranges = chunk_ranges

    def _load_config(self):
        self.conf = files.read_config(self.ngmix_config)
        self.jobs_conf = self.conf['jobs']

    def _make_rng(self, seed=None):
        if seed is None:
            if 'global_seed' not in self.conf:
                raise RuntimeError("either set 'global_seed' in the"
                                   "config or send --seed=")
            seed=self.conf['global_seed']

        self.rng = numpy.random.RandomState(seed=seed)



class SLACMegaMixer(MegaMixer):
    def setup_nbrs(self):
        """
        make directories, write scripts
        """

        print("setting up nbrs scripts")
        self._write_nbrs_script()
        self._write_nbrs_job_script()


    def _make_scripts(self):
        """
        write the scripts and job files
        """
        for chunk,rng in enumerate(self.chunk_ranges):
            self._write_script(chunk, rng)
            self._write_job_script(chunk,rng)

    def _write_job_script(self, chunk, rng):
        fmt=self._get_job_template()
        args = {
            'walltime':self.walltime,
            'walltime_e':self.walltime_e,
            'ncores':self.ncores,
        }

        output_file = self._get_chunk_file(chunk,rng,ext='.fits')
        script_name = self._get_chunk_file(chunk,rng,ext='.sh')

        args['script_name']=script_name

        jobname=os.path.basename(script_name).replace('.sh','')
        args['jobname'] = jobname

        scr = fmt.format(**args)

        script_name = self._get_chunk_file(chunk,rng,ext='.lsf')

        dowrite=True
        if self.missing:
            if os.path.exists(script_name):
                os.remove(script_name)
            if os.path.exists(script_name+'.submitted'):
                #print("removing:",script_name+'.submitted')
                os.remove(script_name+'.submitted')
            if os.path.exists(output_file):
                dowrite=False

        if dowrite:
            print("writing:",script_name)
            with open(script_name,'w') as fp:
                fp.write(scr)

    def _get_job_template(self):

        template=r"""#!/bin/bash
#BSUB -J {jobname}
#BSUB -oo ./{jobname}.oe
#BSUB -n {ncores}
#BSUB -We {walltime_e}
#BSUB -W {walltime}
#BSUB -R "linux64 && rhel60 && scratch > 6"
#BSUB -R span[hosts=1]

export TMPDIR=/scratch/$USER/$LSB_JOBID-$LSB_JOBINDEX

{script_name}
"""

        return template

    def _write_nbrs_job_script(self):
        fmt=self._get_job_template()
        args = {
            'walltime':'4:00',
            'walltime_e':'1:00',
            'ncores':1,
        }


        script_name = self._get_nbrs_file(ext='.sh')

        args['script_name']=script_name

        jobname=os.path.basename(script_name).replace('.sh','')
        args['jobname'] = jobname

        scr = fmt.format(**args)

        script_name = self._get_nbrs_file(ext='.lsf')
        print("writing:",script_name)
        with open(script_name,'w') as fp:
            fp.write(scr)


class BNLMegaMixer(MegaMixer):
    def setup_nbrs(self):
        """
        make directories, write scripts
        """

        print("setting up nbrs scripts")
        self._write_nbrs_script()
        self._write_nbrs_job_script()


    def _get_master_script(self):
        """
        the master script needed for condor
        One executable allowed in condor submit scripts
        """
        return files.get_condor_master_script(
            self.info['tile_id'],
            self.conf['run'],
        )

    def _write_condor_master(self):
        """
        One executable allowed in condor submit scripts
        """

        master_script = self._get_master_script()
        files.makedirs_fromfile(master_script)

        with open(master_script,'w') as fobj:
            text = """#!/bin/bash

# this will be a path to a script
cmd="$1"
$cmd
            \n"""

            fobj.write(text)

        os.system('chmod 755 %s' % master_script)
        

    def _make_scripts(self):
        """
        write the scripts and job file
        """

        self._write_condor_master()
        scripts=[]
        for chunk,rng in enumerate(self.chunk_ranges):
            didwrite, script_name = self._write_script(chunk, rng)

            if didwrite:
                scripts.append(script_name)

        self._write_submit_script(scripts)

    def _write_submit_script(self, scripts):
        """
        write the condor submit script, if there
        were any jobs
        """
        job_script = files.get_condor_submit(
            self.info['tile_id'],
            self.conf['run'],
        )
        if os.path.exists(job_script):
            os.remove(job_script)

        if len(scripts) == 0:
            print("no jobs to write")
            return

        job_fmt=self._get_job_template()

        files.makedirs_fromfile(job_script)
        print("writing condor submit:",job_script)
        with open(job_script,'w') as fobj:

            master_script = self._get_master_script()
            head = self._get_condor_head()
            head = head.format(script=master_script)
            fobj.write(head)


            for script in scripts:
                job_name=os.path.basename(script).replace('.sh','')

                job = job_fmt.format(
                    job_name=job_name,
                    script_name=script,
                )

                fobj.write(job)


    def _get_condor_head(self):
        text="""
Universe        = vanilla

Notification    = Never

# Run this exe with these args
Executable      = {script}

Image_Size       = 1000000

GetEnv = True

kill_sig        = SIGINT


+Experiment     = "astro"\n\n"""
        return text

    def _get_job_template(self):
        return """
+job_name = "{job_name}"
Arguments = {script_name}
Queue\n"""


    def _write_nbrs_job_script(self):

        script_name = self._get_nbrs_file(ext='.sh')
        head=self._get_condor_head()

        head = head.format(script=script_name)

        jobcall = """
+job_name = "{job_name}"
Queue\n"""

        job_name=os.path.basename(script_name).replace('.sh','')
        jobcall=jobcall.format(job_name=job_name)

        job_script_name = self._get_nbrs_file(ext='.condor')
        print("writing:",job_script_name)
        with open(job_script_name,'w') as fp:
            fp.write(head)
            fp.write(jobcall)



def expand_path(path):
    return os.path.abspath(
        os.path.expandvars(
            os.path.expanduser(
                path,
            )
        )
    )


def get_megamixer(system):
    if system == 'shell':
        MMixer = MegaMixer
    elif system == 'slac':
        MMixer = SLACMegaMixer
    elif system=='bnl':
        MMixer = BNLMegaMixer
    else:
        raise ValueError("system %s not supported!" % system)

    return MMixer

def process_meds_files(args, meds_files):

    psf_map_files = [files.get_psfmap_file_fromfile(f) for f in meds_files]

    # get command
    cmd = args.command

    MMixer = get_megamixer(args.system)

    blind = not args.noblind
    ngmm = MMixer(
        args.ngmix_config,
        psf_map_files,
        meds_files,
        seed=args.seed,
        missing=args.missing,
        blind=blind,
        clobber=args.clobber,
        skip_errors=args.skip_errors,
        walltime_e=args.walltime_e,
        walltime=args.walltime,
        ncores=args.ncores,
    )

    if cmd == 'setup':
        ngmm.setup()

    elif cmd=='setup-nbrs':
        ngmm.setup_nbrs()

    elif 'collate' in cmd:
        ngmm.collate()

    elif cmd == 'verify':
        # not yet implemented
        ngmm.verify()

    elif cmd == 'clean':
        # not yet implemented
        ngmm.clean(coadd_run)
    elif cmd == 'archive':
        # not yet implemented
        ngmm.archive(coadd_run,
                     compress=not args.nocompress)
    else:
        raise ValueError("cmd %s not valid!" % cmd)


    
def process_tile_list(args):
    # this is actually a config file
    tile_conf = read_yaml(args.meds_files[0])
    conf=files.read_config(args.ngmix_config)

    if 'tileset' in tile_conf:
        import desmeds
        tileset = desmeds.files.read_tileset(tile_conf['tileset'])

        tiles = tileset['tile_ids']
    else:
        tiles = tile_conf['tile_ids']

    ntiles = len(tiles)

    for i,tile_id in enumerate(tiles):

        print("%d/%d tile id: %s" % (i+1,ntiles,tile_id))

        meds_files = files.get_meds_files(
            tile_conf['medsconf'],
            tile_id,
            conf['jobs']['bands'],
        )

        try:
            process_meds_files(args, meds_files)
        except ngmixer.util.MissingDataError as err:
            if ntiles==1 and not args.skip_errors:
                raise
            print("caught MissingDataError error: %s" % str(err))
        except IOError as err:
            if ntiles==1 and not args.skip_errors:
                raise
            print("caught error: %s" % str(err))
        except ngmixer.megamixer.concat.ConcatError as err:
            if ntiles==1 and not args.skip_errors:
                raise
            print("failed to concatenate tile: %s" % str(err))

def main():

    args = parser.parse_args()

    ngmixer.defaults.VERBOSITY.level = args.verbosity

    if 'yaml' in args.meds_files[0]:
        process_tile_list(args)
    else:
        process_meds_files(args, args.meds_files)

if __name__ == '__main__':
    main()
